===================== train starts ========================
Batch mean loss: 0.6951985359191895 
 Logits:
 [[-0.03786598 -0.0508601 ]
 [-0.03786598 -0.05086009]
 [-0.03786598 -0.0508601 ]
 [-0.03786598 -0.05086009]
 [-0.03786598 -0.05086009]
 [-0.03786598 -0.0508601 ]
 [-0.03786598 -0.05086009]
 [-0.03786598 -0.05086009]
 [-0.03786598 -0.0508601 ]
 [-0.03786598 -0.0508601 ]
 [-0.03786598 -0.0508601 ]
 [-0.03786598 -0.05086009]
 [-0.03786598 -0.05086009]
 [-0.03786598 -0.0508601 ]
 [-0.03786598 -0.0508601 ]
 [-0.03786598 -0.0508601 ]
 [-0.03786598 -0.0508601 ]
 [-0.03786598 -0.0508601 ]
 [-0.03786598 -0.0508601 ]
 [-0.03786598 -0.0508601 ]
 [-0.03786599 -0.05086009]
 [-0.03786598 -0.05086009]
 [-0.03786598 -0.05086009]
 [-0.03786598 -0.05086009]
 [-0.03786598 -0.0508601 ]
 [-0.03786598 -0.05086009]
 [-0.03786598 -0.05086009]
 [-0.03786599 -0.05086009]
 [-0.03786598 -0.05086009]
 [-0.03786598 -0.05086009]
 [-0.03786598 -0.05086009]
 [-0.03786598 -0.0508601 ]] 
 One-hot labels:
 [[ 1.  0.]
 [ 1.  0.]
 [ 0.  1.]
 [ 1.  0.]
 [ 0.  1.]
 [ 0.  1.]
 [ 0.  1.]
 [ 0.  1.]
 [ 1.  0.]
 [ 0.  1.]
 [ 1.  0.]
 [ 0.  1.]
 [ 0.  1.]
 [ 0.  1.]
 [ 0.  1.]
 [ 0.  1.]
 [ 0.  1.]
 [ 1.  0.]
 [ 0.  1.]
 [ 0.  1.]
 [ 0.  1.]
 [ 1.  0.]
 [ 1.  0.]
 [ 0.  1.]
 [ 1.  0.]
 [ 0.  1.]
 [ 0.  1.]
 [ 0.  1.]
 [ 1.  0.]
 [ 0.  1.]
 [ 0.  1.]
 [ 1.  0.]]
