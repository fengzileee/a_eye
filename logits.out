===================== train starts ========================
Batch mean loss: 0.6917334198951721 
 Logits:
 [[-0.03639358 -0.03135547]
 [-0.03639358 -0.03135547]
 [-0.03639358 -0.03135547]
 [-0.03639358 -0.03135548]
 [-0.03639358 -0.03135547]
 [-0.03639358 -0.03135547]
 [-0.03639358 -0.03135547]
 [-0.03639358 -0.03135547]
 [-0.03639358 -0.03135547]
 [-0.03639357 -0.03135548]
 [-0.03639358 -0.03135547]
 [-0.03639358 -0.03135547]
 [-0.03639358 -0.03135547]
 [-0.03639358 -0.03135547]
 [-0.03639358 -0.03135547]
 [-0.03639358 -0.03135547]
 [-0.03639358 -0.03135547]
 [-0.03639358 -0.03135548]
 [-0.03639358 -0.03135548]
 [-0.03639358 -0.03135547]
 [-0.03639357 -0.03135547]
 [-0.03639358 -0.03135547]
 [-0.03639358 -0.03135547]
 [-0.03639358 -0.03135547]
 [-0.03639358 -0.03135547]
 [-0.03639358 -0.03135547]
 [-0.03639358 -0.03135547]
 [-0.03639358 -0.03135547]
 [-0.03639358 -0.03135547]
 [-0.03639358 -0.03135547]
 [-0.03639358 -0.03135547]
 [-0.03639357 -0.03135547]] 
 One-hot labels:
 [[ 1.  0.]
 [ 0.  1.]
 [ 0.  1.]
 [ 0.  1.]
 [ 0.  1.]
 [ 0.  1.]
 [ 0.  1.]
 [ 0.  1.]
 [ 0.  1.]
 [ 0.  1.]
 [ 0.  1.]
 [ 0.  1.]
 [ 0.  1.]
 [ 0.  1.]
 [ 0.  1.]
 [ 0.  1.]
 [ 1.  0.]
 [ 0.  1.]
 [ 1.  0.]
 [ 0.  1.]
 [ 0.  1.]
 [ 0.  1.]
 [ 1.  0.]
 [ 1.  0.]
 [ 0.  1.]
 [ 1.  0.]
 [ 0.  1.]
 [ 0.  1.]
 [ 0.  1.]
 [ 1.  0.]
 [ 0.  1.]
 [ 0.  1.]]
